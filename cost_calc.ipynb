{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models Used & How Cost is Calculated**\n",
    "\n",
    "Inference cost is calculated based on the number of tokens in the input and output. The cost is calculated as follows:\n",
    "```python\n",
    "def calculate_cost(input_tokens, output_tokens, cost_per_token):\n",
    "    return (input_tokens + output_tokens) * cost_per_token\n",
    "```\n",
    "The models we use are defined in `variables.py` under `MODEL_CONFIGS`:\n",
    "```python\n",
    "MODEL_CONFIGS = {\n",
    "    \"openai\": {\n",
    "        \"provider\": \"openai\",\n",
    "        ...\n",
    "    },\n",
    "    \"claude\": {\n",
    "        \"provider\": \"claude\",\n",
    "        ...\n",
    "    },\n",
    "    \"gemini\": {\n",
    "        \"provider\": \"gemini\",\n",
    "        ...\n",
    "    },\n",
    "    \"qwen\": {\n",
    "        \"provider\": \"together\",\n",
    "        ...\n",
    "    },\n",
    "    \"mistral\": {\n",
    "        \"provider\": \"together\",\n",
    "        ...\n",
    "    },\n",
    "    \"llama\": {\n",
    "        \"provider\": \"together\",\n",
    "        ...\n",
    "    },\n",
    "    \"deepseek\": {\n",
    "        \"provider\": \"together\",\n",
    "        ...\n",
    "    },\n",
    "    \"dummy\": {\n",
    "        \"provider\": \"dummy\",\n",
    "        ...\n",
    "    },\n",
    "}\n",
    "```\n",
    "In terms of characters to tokens, 4 characters typically constitute one token. For example, the word \"hello\" is 5 characters long and would be 2 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cost per token**\n",
    "\n",
    "| Model | Input Tokens | Output Tokens | Cached Tokens |\n",
    "|-------|--------------|---------------|---------------|\n",
    "| **GPT-4o-Mini** | $0.15 / 1M | $0.60 / 1M | $0.075 / 1M (cached input) |\n",
    "| **Claude 3.7 Sonnet** | $3.00 / 1M | $15.00 / 1M | $3.75 / 1M (cached write)<br>$0.30 / 1M (cached read) |\n",
    "| **Gemini 2.0 Flash** | $0.10 / 1M | $0.40 / 1M | $0.025 / 1M |\n",
    "| **Qwen2.5-7B-Instruct** | $0.30 / 1M (general price) | $0.30 / 1M (general price) | - |\n",
    "| **Mistral 7B Instruct** | $0.20 / 1M (general price) | $0.20 / 1M (general price) | - |\n",
    "| **Llama-3.3-70B-Instruct-Turbo** | $0.88 / 1M (general price) | $0.88 / 1M (general price) | - |\n",
    "| **DeepSeek-R1-Distill-Llama-70B** | $2.00 / 1M (general price) | $2.00 / 1M (general price) | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cost Analysis for Our Prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Estimate the number of tokens in text using 4 chars ≈ 1 token rule\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "def calculate_prompt_cost(prompt: str, output_tokens: int = 25) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the cost of running a prompt through different models\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt text\n",
    "        output_tokens: Estimated number of tokens in the model's response\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with cost estimates for each model\n",
    "    \"\"\"\n",
    "    # Estimate tokens\n",
    "    input_tokens = estimate_tokens(prompt)\n",
    "    \n",
    "    # Cost per million tokens (input, output)\n",
    "    costs = {\n",
    "        \"GPT-4o-Mini\": {\n",
    "            \"input_rate\": 0.15,    # per 1M tokens\n",
    "            \"output_rate\": 0.60,   # per 1M tokens\n",
    "        },\n",
    "        \"Claude 3.7 Sonnet\": {\n",
    "            \"input_rate\": 3.00,\n",
    "            \"output_rate\": 15.00,\n",
    "        },\n",
    "        \"Gemini 2.0 Flash\": {\n",
    "            \"input_rate\": 0.10,\n",
    "            \"output_rate\": 0.40,\n",
    "        },\n",
    "        \"Qwen 2.5 7B Instruct\": {\n",
    "            \"input_rate\": 0.30,\n",
    "            \"output_rate\": 0.30,\n",
    "        },\n",
    "        \"Mistral 7B Instruct\": {\n",
    "            \"input_rate\": 0.20,\n",
    "            \"output_rate\": 0.20,\n",
    "        },\n",
    "        \"LLama 3.3 70B Instruct Turbo\": {\n",
    "            \"input_rate\": 0.88,\n",
    "            \"output_rate\": 0.88,\n",
    "        },\n",
    "        \"DeepSeek R1 Distilled Llama 70B\": {\n",
    "            \"input_rate\": 2.00,\n",
    "            \"output_rate\": 2.00,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model, rates in costs.items():\n",
    "        input_cost = (input_tokens / 1_000_000) * rates[\"input_rate\"]\n",
    "        output_cost = (output_tokens / 1_000_000) * rates[\"output_rate\"]\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        results[model] = {\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"input_cost\": input_cost,\n",
    "            \"output_cost\": output_cost,\n",
    "            \"total_cost\": total_cost\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_styled_df(df, caption=None, highlight_cheapest=True):\n",
    "    \"\"\"\n",
    "    Display styled DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame to style\n",
    "        caption: Optional caption for the table\n",
    "        highlight_cheapest: Whether to highlight the cheapest model row\n",
    "    \"\"\"\n",
    "    # Define styling\n",
    "    def style_df(styler):\n",
    "        # Convert numbers to strings with commas for better readability\n",
    "        if 'Total Input Tokens' in df.columns:\n",
    "            df_copy = df.copy()\n",
    "            for col in ['Total Input Tokens', 'Total Output Tokens']:\n",
    "                if col in df_copy.columns:\n",
    "                    df_copy[col] = df_copy[col].apply(lambda x: f\"{int(x):,}\" if isinstance(x, (int, float)) else x)\n",
    "        else:\n",
    "            df_copy = df\n",
    "        \n",
    "        # Apply formatting to numbers\n",
    "        format_dict = {}\n",
    "        for col in df_copy.columns:\n",
    "            if 'Cost ($)' in col or 'Cost per Prompt' in col:\n",
    "                format_dict[col] = \"${:.8f}\"\n",
    "            elif 'Total Cost' in col:\n",
    "                format_dict[col] = \"${:.4f}\"\n",
    "            \n",
    "        # Base styling\n",
    "        styler = pd.DataFrame(df_copy).style.format(format_dict)\n",
    "        \n",
    "        # Highlight the cheapest model if requested\n",
    "        if highlight_cheapest and 'Total Cost ($)' in df_copy.columns:\n",
    "            min_cost_idx = df_copy['Total Cost ($)'].astype(float).idxmin()\n",
    "            styler = styler.apply(lambda x: ['background-color: #2a4b34' if i == min_cost_idx else '' for i in range(len(x))], axis=0)\n",
    "        \n",
    "        # Apply themed styling for dark mode\n",
    "        return styler.set_properties(**{\n",
    "            'text-align': 'center',\n",
    "            'border': '1px solid #555',\n",
    "            'padding': '5px',\n",
    "            'background-color': '#1e1e1e',\n",
    "            'color': '#e0e0e0'\n",
    "        }).set_table_styles([{\n",
    "            'selector': 'th',\n",
    "            'props': [('background-color', '#2d2d2d'), \n",
    "                     ('text-align', 'center'),\n",
    "                     ('font-weight', 'bold'),\n",
    "                     ('border', '1px solid #555'),\n",
    "                     ('color', '#e0e0e0'),\n",
    "                     ('padding', '5px')]\n",
    "        }, {\n",
    "            'selector': 'caption',\n",
    "            'props': [('caption-side', 'top'),\n",
    "                      ('font-size', '1.1em'),\n",
    "                      ('font-weight', 'bold'),\n",
    "                      ('color', '#d0d0d0'),\n",
    "                      ('padding', '8px')]\n",
    "        }]).set_caption(caption)\n",
    "    \n",
    "    display(style_df(df.style))\n",
    "\n",
    "def analyze_prompt_cost(prompt: str, expected_output_length: int = 100):\n",
    "    \"\"\"\n",
    "    Analyze and print the cost of a prompt across different models\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt text\n",
    "        expected_output_length: Expected length in CHARACTERS of the output\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cost estimates for each model\n",
    "    \"\"\"\n",
    "    # Add section header with nice formatting\n",
    "    display(HTML(\"<hr style='border: 2px solid #4a86e8; margin: 20px 0;'>\"))\n",
    "    display(Markdown(\"## Single Prompt Cost Analysis\"))\n",
    "    \n",
    "    # Convert expected output length in characters to tokens\n",
    "    expected_output_tokens = expected_output_length // 4\n",
    "    \n",
    "    results = calculate_prompt_cost(prompt, expected_output_tokens)\n",
    "    \n",
    "    # Display prompt information\n",
    "    info_html = f\"\"\"\n",
    "    <div style='background-color: #2d2d2d; padding: 10px; border-left: 4px solid #4a86e8; margin-bottom: 15px;'>\n",
    "        <p><b>Prompt length:</b> {len(prompt):,} characters ≈ {estimate_tokens(prompt):,} tokens</p>\n",
    "        <p><b>Expected output:</b> {expected_output_length:,} characters ≈ {expected_output_tokens:,} tokens</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(info_html))\n",
    "    \n",
    "    # Create data for DataFrame\n",
    "    data = []\n",
    "    for model, res in results.items():\n",
    "        data.append({\n",
    "            \"Model\": model,\n",
    "            \"Input Tokens\": res[\"input_tokens\"],\n",
    "            \"Output Tokens\": res[\"output_tokens\"],\n",
    "            \"Input Cost ($)\": res[\"input_cost\"],\n",
    "            \"Output Cost ($)\": res[\"output_cost\"],\n",
    "            \"Total Cost ($)\": res[\"total_cost\"]\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and display with styling\n",
    "    df = pd.DataFrame(data)\n",
    "    display_styled_df(df, caption=\"Cost per Model for Single Prompt\", highlight_cheapest=True)\n",
    "    \n",
    "    # Find the cheapest model\n",
    "    cheapest = min(results.items(), key=lambda x: x[1]['total_cost'])\n",
    "    cheapest_html = f\"\"\"\n",
    "    <div style='background-color: #2a4b34; padding: 10px; border-left: 4px solid #4ac656; margin-top: 15px;'>\n",
    "        <p><b>Cheapest model:</b> {cheapest[0]} (${cheapest[1]['total_cost']:.8f})</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(cheapest_html))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_pipeline_cost(\n",
    "    prompt_text: str,\n",
    "    analysis_type: str = \"functions\",\n",
    "    species_count: int = 1,\n",
    "    regions_per_species: int = 34,\n",
    "    hemisphere_separation: bool = True,\n",
    "    functions_count: int = 5,\n",
    "    expected_output_length: int = 100,\n",
    "    models_to_analyze: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze the cost of an entire analysis pipeline\n",
    "    \n",
    "    Args:\n",
    "        prompt_text: Example prompt text to use for token estimation\n",
    "        analysis_type: Type of analysis (\"functions\" or \"probability\")\n",
    "        species_count: Number of species to analyze\n",
    "        regions_per_species: Number of brain regions per species\n",
    "        hemisphere_separation: Whether to analyze hemispheres separately\n",
    "        functions_count: Number of functions to analyze (for probability analysis)\n",
    "        expected_output_length: Expected output length in characters\n",
    "        models_to_analyze: List of models to include in analysis (None = all)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with cost estimates for the entire pipeline\n",
    "    \"\"\"\n",
    "    # Add section header with nice formatting\n",
    "    display(HTML(\"<hr style='border: 2px solid #4a86e8; margin: 20px 0;'>\"))\n",
    "    display(Markdown(f\"## Pipeline Cost Analysis for {analysis_type.capitalize()}\"))\n",
    "    \n",
    "    # Validate analysis type\n",
    "    if analysis_type not in [\"functions\", \"probability\"]:\n",
    "        raise ValueError(\"Analysis type must be 'functions' or 'probability'\")\n",
    "    \n",
    "    # Convert expected output length to tokens\n",
    "    expected_output_tokens = expected_output_length // 4\n",
    "    \n",
    "    # Calculate total prompt runs\n",
    "    hemispheres = 2 if hemisphere_separation else 1\n",
    "    \n",
    "    if analysis_type == \"functions\":\n",
    "        total_prompts = species_count * regions_per_species * hemispheres\n",
    "    else:  # probability\n",
    "        total_prompts = species_count * regions_per_species * hemispheres * functions_count\n",
    "    \n",
    "    # Calculate cost per prompt\n",
    "    prompt_costs = calculate_prompt_cost(prompt_text, expected_output_tokens)\n",
    "    \n",
    "    # Filter models if specified\n",
    "    if models_to_analyze:\n",
    "        prompt_costs = {model: cost for model, cost in prompt_costs.items() if model in models_to_analyze}\n",
    "    \n",
    "    # Calculate pipeline costs\n",
    "    pipeline_costs = {}\n",
    "    for model, cost_data in prompt_costs.items():\n",
    "        per_prompt_cost = cost_data[\"total_cost\"]\n",
    "        total_cost = per_prompt_cost * total_prompts\n",
    "        \n",
    "        pipeline_costs[model] = {\n",
    "            \"per_prompt_cost\": per_prompt_cost,\n",
    "            \"total_prompts\": total_prompts,\n",
    "            \"total_cost\": total_cost,\n",
    "            \"input_tokens_total\": cost_data[\"input_tokens\"] * total_prompts,\n",
    "            \"output_tokens_total\": cost_data[\"output_tokens\"] * total_prompts\n",
    "        }\n",
    "    \n",
    "    # Display pipeline information\n",
    "    info_html = f\"\"\"\n",
    "    <div style='background-color: #2d2d2d; padding: 10px; border-left: 4px solid #4a86e8; margin-bottom: 15px;'>\n",
    "        <p><b>Species:</b> {species_count}</p>\n",
    "        <p><b>Regions per species:</b> {regions_per_species}</p>\n",
    "        <p><b>Hemisphere separation:</b> {'Yes' if hemisphere_separation else 'No'}</p>\n",
    "    \"\"\"\n",
    "    \n",
    "    if analysis_type == \"probability\":\n",
    "        info_html += f\"<p><b>Functions per region:</b> {functions_count}</p>\"\n",
    "    \n",
    "    info_html += f\"\"\"\n",
    "        <p><b>Total prompts to run:</b> {total_prompts:,}</p>\n",
    "        <p><b>Prompt length:</b> {len(prompt_text):,} characters ≈ {estimate_tokens(prompt_text):,} tokens</p>\n",
    "        <p><b>Expected output:</b> {expected_output_length:,} characters ≈ {expected_output_tokens:,} tokens</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(info_html))\n",
    "    \n",
    "    # Create formatted data for display\n",
    "    data = []\n",
    "    for model, cost_data in pipeline_costs.items():\n",
    "        data.append({\n",
    "            \"Model\": model,\n",
    "            \"Cost per Prompt ($)\": cost_data['per_prompt_cost'],\n",
    "            \"Total Prompts\": cost_data[\"total_prompts\"],\n",
    "            \"Total Cost ($)\": cost_data[\"total_cost\"],\n",
    "            \"Total Input Tokens\": cost_data[\"input_tokens_total\"],\n",
    "            \"Total Output Tokens\": cost_data[\"output_tokens_total\"]\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and display with styling\n",
    "    df = pd.DataFrame(data)\n",
    "    display_styled_df(df, caption=f\"Total Cost per Model for {analysis_type.capitalize()} Pipeline\", highlight_cheapest=True)\n",
    "    \n",
    "    # Find cheapest model\n",
    "    cheapest = min(pipeline_costs.items(), key=lambda x: x[1]['total_cost'])\n",
    "    \n",
    "    cheapest_html = f\"\"\"\n",
    "    <div style='background-color: #2a4b34; padding: 10px; border-left: 4px solid #4ac656; margin-top: 15px;'>\n",
    "        <p><b>Cheapest model for pipeline:</b> {cheapest[0]}</p>\n",
    "        <p><b>Estimated total cost:</b> ${cheapest[1]['total_cost']:.4f}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(cheapest_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function prompt\n",
    "function_prompt = \"\"\"\n",
    "You are an expert in neuroscience literature analysis. Your task is to\n",
    "list out the top 5 functions that region **hippocampus** in the **left\n",
    "hemisphere** of the **human** brain is involved in.\n",
    "\n",
    "These functions should be based on a simulated review of neuroscience\n",
    "literature, reflecting how frequently these functions are associated with\n",
    "this brain region across **peer-reviewed** studies, textbooks, and\n",
    "reputable sources.\n",
    "\n",
    "### Guidelines\n",
    "1. Consider only **human**-specific neuroscience literature. Do **not**\n",
    "use data from other species.\n",
    "2. **DO NOT** provide explanations, citations, or any extra text—**return\n",
    "only the function names**.\n",
    "3. Return your results as a list: [function_1, function_2, function_3,\n",
    "function_4, function_5]\n",
    "4. **DO NOT** repeat functions in your list.\n",
    "5. List out the functions **only** for the specified left\n",
    "hemisphere.\n",
    "\n",
    "### Expected Output Format\n",
    "[function_1, function_2, function_3, function_4, function_5]\n",
    "\"\"\"\n",
    "\n",
    "# Example probability prompt\n",
    "probability_prompt = \"\"\"\n",
    "You are an expert in neuroscience literature analysis. Your task is to\n",
    "estimate the probability that the brain region **amygdala** in the **\n",
    "left hemisphere** of the **human** brain is involved in **\n",
    "fear processing**.\n",
    "\n",
    "These functions should be based on a simulated review of neuroscience\n",
    "literature, reflecting how frequently these functions are associated with\n",
    "this brain region across **peer-reviewed** studies, textbooks, and\n",
    "reputable sources.\n",
    "\n",
    "### Guidelines\n",
    "1. Consider only **human**-specific neuroscience literature. Do\n",
    "**not** use data from other species.\n",
    "2. The probability should be a **single decimal number** between **0 and\n",
    "1**.\n",
    "3. This number should **approximate the relative frequency** with which\n",
    "this function is linked to the given brain region in literature.\n",
    "4. **DO NOT** provide explanations, citations, or any extra text—**return\n",
    "only the probability value**.\n",
    "\n",
    "### Expected Output Format\n",
    "0.XX\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr style='border: 2px solid #4a86e8; margin: 20px 0;'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Single Prompt Cost Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2d2d2d; padding: 10px; border-left: 4px solid #4a86e8; margin-bottom: 15px;'>\n",
       "        <p><b>Prompt length:</b> 943 characters ≈ 235 tokens</p>\n",
       "        <p><b>Expected output:</b> 100 characters ≈ 25 tokens</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83f76 th {\n",
       "  background-color: #2d2d2d;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  border: 1px solid #555;\n",
       "  color: #e0e0e0;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_83f76 caption {\n",
       "  caption-side: top;\n",
       "  font-size: 1.1em;\n",
       "  font-weight: bold;\n",
       "  color: #d0d0d0;\n",
       "  padding: 8px;\n",
       "}\n",
       "#T_83f76_row0_col0, #T_83f76_row0_col1, #T_83f76_row0_col2, #T_83f76_row0_col3, #T_83f76_row0_col4, #T_83f76_row0_col5, #T_83f76_row1_col0, #T_83f76_row1_col1, #T_83f76_row1_col2, #T_83f76_row1_col3, #T_83f76_row1_col4, #T_83f76_row1_col5, #T_83f76_row3_col0, #T_83f76_row3_col1, #T_83f76_row3_col2, #T_83f76_row3_col3, #T_83f76_row3_col4, #T_83f76_row3_col5, #T_83f76_row4_col0, #T_83f76_row4_col1, #T_83f76_row4_col2, #T_83f76_row4_col3, #T_83f76_row4_col4, #T_83f76_row4_col5, #T_83f76_row5_col0, #T_83f76_row5_col1, #T_83f76_row5_col2, #T_83f76_row5_col3, #T_83f76_row5_col4, #T_83f76_row5_col5, #T_83f76_row6_col0, #T_83f76_row6_col1, #T_83f76_row6_col2, #T_83f76_row6_col3, #T_83f76_row6_col4, #T_83f76_row6_col5 {\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "#T_83f76_row2_col0, #T_83f76_row2_col1, #T_83f76_row2_col2, #T_83f76_row2_col3, #T_83f76_row2_col4, #T_83f76_row2_col5 {\n",
       "  background-color: #2a4b34;\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83f76\">\n",
       "  <caption>Cost per Model for Single Prompt</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83f76_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_83f76_level0_col1\" class=\"col_heading level0 col1\" >Input Tokens</th>\n",
       "      <th id=\"T_83f76_level0_col2\" class=\"col_heading level0 col2\" >Output Tokens</th>\n",
       "      <th id=\"T_83f76_level0_col3\" class=\"col_heading level0 col3\" >Input Cost ($)</th>\n",
       "      <th id=\"T_83f76_level0_col4\" class=\"col_heading level0 col4\" >Output Cost ($)</th>\n",
       "      <th id=\"T_83f76_level0_col5\" class=\"col_heading level0 col5\" >Total Cost ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_83f76_row0_col0\" class=\"data row0 col0\" >GPT-4o-Mini</td>\n",
       "      <td id=\"T_83f76_row0_col1\" class=\"data row0 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row0_col2\" class=\"data row0 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row0_col3\" class=\"data row0 col3\" >$0.00003525</td>\n",
       "      <td id=\"T_83f76_row0_col4\" class=\"data row0 col4\" >$0.00001500</td>\n",
       "      <td id=\"T_83f76_row0_col5\" class=\"data row0 col5\" >$0.00005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_83f76_row1_col0\" class=\"data row1 col0\" >Claude 3.7 Sonnet</td>\n",
       "      <td id=\"T_83f76_row1_col1\" class=\"data row1 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row1_col2\" class=\"data row1 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row1_col3\" class=\"data row1 col3\" >$0.00070500</td>\n",
       "      <td id=\"T_83f76_row1_col4\" class=\"data row1 col4\" >$0.00037500</td>\n",
       "      <td id=\"T_83f76_row1_col5\" class=\"data row1 col5\" >$0.00108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_83f76_row2_col0\" class=\"data row2 col0\" >Gemini 2.0 Flash</td>\n",
       "      <td id=\"T_83f76_row2_col1\" class=\"data row2 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row2_col2\" class=\"data row2 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row2_col3\" class=\"data row2 col3\" >$0.00002350</td>\n",
       "      <td id=\"T_83f76_row2_col4\" class=\"data row2 col4\" >$0.00001000</td>\n",
       "      <td id=\"T_83f76_row2_col5\" class=\"data row2 col5\" >$0.00003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_83f76_row3_col0\" class=\"data row3 col0\" >Qwen 2.5 7B Instruct</td>\n",
       "      <td id=\"T_83f76_row3_col1\" class=\"data row3 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row3_col2\" class=\"data row3 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row3_col3\" class=\"data row3 col3\" >$0.00007050</td>\n",
       "      <td id=\"T_83f76_row3_col4\" class=\"data row3 col4\" >$0.00000750</td>\n",
       "      <td id=\"T_83f76_row3_col5\" class=\"data row3 col5\" >$0.00007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_83f76_row4_col0\" class=\"data row4 col0\" >Mistral 7B Instruct</td>\n",
       "      <td id=\"T_83f76_row4_col1\" class=\"data row4 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row4_col2\" class=\"data row4 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row4_col3\" class=\"data row4 col3\" >$0.00004700</td>\n",
       "      <td id=\"T_83f76_row4_col4\" class=\"data row4 col4\" >$0.00000500</td>\n",
       "      <td id=\"T_83f76_row4_col5\" class=\"data row4 col5\" >$0.00005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_83f76_row5_col0\" class=\"data row5 col0\" >LLama 3.3 70B Instruct Turbo</td>\n",
       "      <td id=\"T_83f76_row5_col1\" class=\"data row5 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row5_col2\" class=\"data row5 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row5_col3\" class=\"data row5 col3\" >$0.00020680</td>\n",
       "      <td id=\"T_83f76_row5_col4\" class=\"data row5 col4\" >$0.00002200</td>\n",
       "      <td id=\"T_83f76_row5_col5\" class=\"data row5 col5\" >$0.00022880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f76_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_83f76_row6_col0\" class=\"data row6 col0\" >DeepSeek R1 Distilled Llama 70B</td>\n",
       "      <td id=\"T_83f76_row6_col1\" class=\"data row6 col1\" >235</td>\n",
       "      <td id=\"T_83f76_row6_col2\" class=\"data row6 col2\" >25</td>\n",
       "      <td id=\"T_83f76_row6_col3\" class=\"data row6 col3\" >$0.00047000</td>\n",
       "      <td id=\"T_83f76_row6_col4\" class=\"data row6 col4\" >$0.00005000</td>\n",
       "      <td id=\"T_83f76_row6_col5\" class=\"data row6 col5\" >$0.00052000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124904ce0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2a4b34; padding: 10px; border-left: 4px solid #4ac656; margin-top: 15px;'>\n",
       "        <p><b>Cheapest model:</b> Gemini 2.0 Flash ($0.00003350)</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr style='border: 2px solid #4a86e8; margin: 20px 0;'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Pipeline Cost Analysis for Functions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2d2d2d; padding: 10px; border-left: 4px solid #4a86e8; margin-bottom: 15px;'>\n",
       "        <p><b>Species:</b> 3</p>\n",
       "        <p><b>Regions per species:</b> 34</p>\n",
       "        <p><b>Hemisphere separation:</b> Yes</p>\n",
       "    \n",
       "        <p><b>Total prompts to run:</b> 204</p>\n",
       "        <p><b>Prompt length:</b> 943 characters ≈ 235 tokens</p>\n",
       "        <p><b>Expected output:</b> 100 characters ≈ 25 tokens</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_29b93 th {\n",
       "  background-color: #2d2d2d;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  border: 1px solid #555;\n",
       "  color: #e0e0e0;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_29b93 caption {\n",
       "  caption-side: top;\n",
       "  font-size: 1.1em;\n",
       "  font-weight: bold;\n",
       "  color: #d0d0d0;\n",
       "  padding: 8px;\n",
       "}\n",
       "#T_29b93_row0_col0, #T_29b93_row0_col1, #T_29b93_row0_col2, #T_29b93_row0_col3, #T_29b93_row0_col4, #T_29b93_row0_col5, #T_29b93_row1_col0, #T_29b93_row1_col1, #T_29b93_row1_col2, #T_29b93_row1_col3, #T_29b93_row1_col4, #T_29b93_row1_col5, #T_29b93_row3_col0, #T_29b93_row3_col1, #T_29b93_row3_col2, #T_29b93_row3_col3, #T_29b93_row3_col4, #T_29b93_row3_col5, #T_29b93_row4_col0, #T_29b93_row4_col1, #T_29b93_row4_col2, #T_29b93_row4_col3, #T_29b93_row4_col4, #T_29b93_row4_col5, #T_29b93_row5_col0, #T_29b93_row5_col1, #T_29b93_row5_col2, #T_29b93_row5_col3, #T_29b93_row5_col4, #T_29b93_row5_col5, #T_29b93_row6_col0, #T_29b93_row6_col1, #T_29b93_row6_col2, #T_29b93_row6_col3, #T_29b93_row6_col4, #T_29b93_row6_col5 {\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "#T_29b93_row2_col0, #T_29b93_row2_col1, #T_29b93_row2_col2, #T_29b93_row2_col3, #T_29b93_row2_col4, #T_29b93_row2_col5 {\n",
       "  background-color: #2a4b34;\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_29b93\">\n",
       "  <caption>Total Cost per Model for Functions Pipeline</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_29b93_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_29b93_level0_col1\" class=\"col_heading level0 col1\" >Cost per Prompt ($)</th>\n",
       "      <th id=\"T_29b93_level0_col2\" class=\"col_heading level0 col2\" >Total Prompts</th>\n",
       "      <th id=\"T_29b93_level0_col3\" class=\"col_heading level0 col3\" >Total Cost ($)</th>\n",
       "      <th id=\"T_29b93_level0_col4\" class=\"col_heading level0 col4\" >Total Input Tokens</th>\n",
       "      <th id=\"T_29b93_level0_col5\" class=\"col_heading level0 col5\" >Total Output Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_29b93_row0_col0\" class=\"data row0 col0\" >GPT-4o-Mini</td>\n",
       "      <td id=\"T_29b93_row0_col1\" class=\"data row0 col1\" >$0.00005025</td>\n",
       "      <td id=\"T_29b93_row0_col2\" class=\"data row0 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row0_col3\" class=\"data row0 col3\" >$0.01025100</td>\n",
       "      <td id=\"T_29b93_row0_col4\" class=\"data row0 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row0_col5\" class=\"data row0 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_29b93_row1_col0\" class=\"data row1 col0\" >Claude 3.7 Sonnet</td>\n",
       "      <td id=\"T_29b93_row1_col1\" class=\"data row1 col1\" >$0.00108000</td>\n",
       "      <td id=\"T_29b93_row1_col2\" class=\"data row1 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row1_col3\" class=\"data row1 col3\" >$0.22032000</td>\n",
       "      <td id=\"T_29b93_row1_col4\" class=\"data row1 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row1_col5\" class=\"data row1 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_29b93_row2_col0\" class=\"data row2 col0\" >Gemini 2.0 Flash</td>\n",
       "      <td id=\"T_29b93_row2_col1\" class=\"data row2 col1\" >$0.00003350</td>\n",
       "      <td id=\"T_29b93_row2_col2\" class=\"data row2 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row2_col3\" class=\"data row2 col3\" >$0.00683400</td>\n",
       "      <td id=\"T_29b93_row2_col4\" class=\"data row2 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row2_col5\" class=\"data row2 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_29b93_row3_col0\" class=\"data row3 col0\" >Qwen 2.5 7B Instruct</td>\n",
       "      <td id=\"T_29b93_row3_col1\" class=\"data row3 col1\" >$0.00007800</td>\n",
       "      <td id=\"T_29b93_row3_col2\" class=\"data row3 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row3_col3\" class=\"data row3 col3\" >$0.01591200</td>\n",
       "      <td id=\"T_29b93_row3_col4\" class=\"data row3 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row3_col5\" class=\"data row3 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_29b93_row4_col0\" class=\"data row4 col0\" >Mistral 7B Instruct</td>\n",
       "      <td id=\"T_29b93_row4_col1\" class=\"data row4 col1\" >$0.00005200</td>\n",
       "      <td id=\"T_29b93_row4_col2\" class=\"data row4 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row4_col3\" class=\"data row4 col3\" >$0.01060800</td>\n",
       "      <td id=\"T_29b93_row4_col4\" class=\"data row4 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row4_col5\" class=\"data row4 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_29b93_row5_col0\" class=\"data row5 col0\" >LLama 3.3 70B Instruct Turbo</td>\n",
       "      <td id=\"T_29b93_row5_col1\" class=\"data row5 col1\" >$0.00022880</td>\n",
       "      <td id=\"T_29b93_row5_col2\" class=\"data row5 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row5_col3\" class=\"data row5 col3\" >$0.04667520</td>\n",
       "      <td id=\"T_29b93_row5_col4\" class=\"data row5 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row5_col5\" class=\"data row5 col5\" >5,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29b93_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_29b93_row6_col0\" class=\"data row6 col0\" >DeepSeek R1 Distilled Llama 70B</td>\n",
       "      <td id=\"T_29b93_row6_col1\" class=\"data row6 col1\" >$0.00052000</td>\n",
       "      <td id=\"T_29b93_row6_col2\" class=\"data row6 col2\" >204</td>\n",
       "      <td id=\"T_29b93_row6_col3\" class=\"data row6 col3\" >$0.10608000</td>\n",
       "      <td id=\"T_29b93_row6_col4\" class=\"data row6 col4\" >47,940</td>\n",
       "      <td id=\"T_29b93_row6_col5\" class=\"data row6 col5\" >5,100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120ef7bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2a4b34; padding: 10px; border-left: 4px solid #4ac656; margin-top: 15px;'>\n",
       "        <p><b>Cheapest model for pipeline:</b> Gemini 2.0 Flash</p>\n",
       "        <p><b>Estimated total cost:</b> $0.0068</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr style='border: 2px solid #4a86e8; margin: 20px 0;'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Pipeline Cost Analysis for Probability"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2d2d2d; padding: 10px; border-left: 4px solid #4a86e8; margin-bottom: 15px;'>\n",
       "        <p><b>Species:</b> 3</p>\n",
       "        <p><b>Regions per species:</b> 34</p>\n",
       "        <p><b>Hemisphere separation:</b> Yes</p>\n",
       "    <p><b>Functions per region:</b> 5</p>\n",
       "        <p><b>Total prompts to run:</b> 1,020</p>\n",
       "        <p><b>Prompt length:</b> 920 characters ≈ 230 tokens</p>\n",
       "        <p><b>Expected output:</b> 4 characters ≈ 1 tokens</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_33c0e th {\n",
       "  background-color: #2d2d2d;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  border: 1px solid #555;\n",
       "  color: #e0e0e0;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_33c0e caption {\n",
       "  caption-side: top;\n",
       "  font-size: 1.1em;\n",
       "  font-weight: bold;\n",
       "  color: #d0d0d0;\n",
       "  padding: 8px;\n",
       "}\n",
       "#T_33c0e_row0_col0, #T_33c0e_row0_col1, #T_33c0e_row0_col2, #T_33c0e_row0_col3, #T_33c0e_row0_col4, #T_33c0e_row0_col5, #T_33c0e_row1_col0, #T_33c0e_row1_col1, #T_33c0e_row1_col2, #T_33c0e_row1_col3, #T_33c0e_row1_col4, #T_33c0e_row1_col5, #T_33c0e_row3_col0, #T_33c0e_row3_col1, #T_33c0e_row3_col2, #T_33c0e_row3_col3, #T_33c0e_row3_col4, #T_33c0e_row3_col5, #T_33c0e_row4_col0, #T_33c0e_row4_col1, #T_33c0e_row4_col2, #T_33c0e_row4_col3, #T_33c0e_row4_col4, #T_33c0e_row4_col5, #T_33c0e_row5_col0, #T_33c0e_row5_col1, #T_33c0e_row5_col2, #T_33c0e_row5_col3, #T_33c0e_row5_col4, #T_33c0e_row5_col5, #T_33c0e_row6_col0, #T_33c0e_row6_col1, #T_33c0e_row6_col2, #T_33c0e_row6_col3, #T_33c0e_row6_col4, #T_33c0e_row6_col5 {\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "#T_33c0e_row2_col0, #T_33c0e_row2_col1, #T_33c0e_row2_col2, #T_33c0e_row2_col3, #T_33c0e_row2_col4, #T_33c0e_row2_col5 {\n",
       "  background-color: #2a4b34;\n",
       "  text-align: center;\n",
       "  border: 1px solid #555;\n",
       "  padding: 5px;\n",
       "  background-color: #1e1e1e;\n",
       "  color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_33c0e\">\n",
       "  <caption>Total Cost per Model for Probability Pipeline</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_33c0e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_33c0e_level0_col1\" class=\"col_heading level0 col1\" >Cost per Prompt ($)</th>\n",
       "      <th id=\"T_33c0e_level0_col2\" class=\"col_heading level0 col2\" >Total Prompts</th>\n",
       "      <th id=\"T_33c0e_level0_col3\" class=\"col_heading level0 col3\" >Total Cost ($)</th>\n",
       "      <th id=\"T_33c0e_level0_col4\" class=\"col_heading level0 col4\" >Total Input Tokens</th>\n",
       "      <th id=\"T_33c0e_level0_col5\" class=\"col_heading level0 col5\" >Total Output Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_33c0e_row0_col0\" class=\"data row0 col0\" >GPT-4o-Mini</td>\n",
       "      <td id=\"T_33c0e_row0_col1\" class=\"data row0 col1\" >$0.00003510</td>\n",
       "      <td id=\"T_33c0e_row0_col2\" class=\"data row0 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row0_col3\" class=\"data row0 col3\" >$0.03580200</td>\n",
       "      <td id=\"T_33c0e_row0_col4\" class=\"data row0 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row0_col5\" class=\"data row0 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_33c0e_row1_col0\" class=\"data row1 col0\" >Claude 3.7 Sonnet</td>\n",
       "      <td id=\"T_33c0e_row1_col1\" class=\"data row1 col1\" >$0.00070500</td>\n",
       "      <td id=\"T_33c0e_row1_col2\" class=\"data row1 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row1_col3\" class=\"data row1 col3\" >$0.71910000</td>\n",
       "      <td id=\"T_33c0e_row1_col4\" class=\"data row1 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row1_col5\" class=\"data row1 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_33c0e_row2_col0\" class=\"data row2 col0\" >Gemini 2.0 Flash</td>\n",
       "      <td id=\"T_33c0e_row2_col1\" class=\"data row2 col1\" >$0.00002340</td>\n",
       "      <td id=\"T_33c0e_row2_col2\" class=\"data row2 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row2_col3\" class=\"data row2 col3\" >$0.02386800</td>\n",
       "      <td id=\"T_33c0e_row2_col4\" class=\"data row2 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row2_col5\" class=\"data row2 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_33c0e_row3_col0\" class=\"data row3 col0\" >Qwen 2.5 7B Instruct</td>\n",
       "      <td id=\"T_33c0e_row3_col1\" class=\"data row3 col1\" >$0.00006930</td>\n",
       "      <td id=\"T_33c0e_row3_col2\" class=\"data row3 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row3_col3\" class=\"data row3 col3\" >$0.07068600</td>\n",
       "      <td id=\"T_33c0e_row3_col4\" class=\"data row3 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row3_col5\" class=\"data row3 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_33c0e_row4_col0\" class=\"data row4 col0\" >Mistral 7B Instruct</td>\n",
       "      <td id=\"T_33c0e_row4_col1\" class=\"data row4 col1\" >$0.00004620</td>\n",
       "      <td id=\"T_33c0e_row4_col2\" class=\"data row4 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row4_col3\" class=\"data row4 col3\" >$0.04712400</td>\n",
       "      <td id=\"T_33c0e_row4_col4\" class=\"data row4 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row4_col5\" class=\"data row4 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_33c0e_row5_col0\" class=\"data row5 col0\" >LLama 3.3 70B Instruct Turbo</td>\n",
       "      <td id=\"T_33c0e_row5_col1\" class=\"data row5 col1\" >$0.00020328</td>\n",
       "      <td id=\"T_33c0e_row5_col2\" class=\"data row5 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row5_col3\" class=\"data row5 col3\" >$0.20734560</td>\n",
       "      <td id=\"T_33c0e_row5_col4\" class=\"data row5 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row5_col5\" class=\"data row5 col5\" >1,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33c0e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_33c0e_row6_col0\" class=\"data row6 col0\" >DeepSeek R1 Distilled Llama 70B</td>\n",
       "      <td id=\"T_33c0e_row6_col1\" class=\"data row6 col1\" >$0.00046200</td>\n",
       "      <td id=\"T_33c0e_row6_col2\" class=\"data row6 col2\" >1020</td>\n",
       "      <td id=\"T_33c0e_row6_col3\" class=\"data row6 col3\" >$0.47124000</td>\n",
       "      <td id=\"T_33c0e_row6_col4\" class=\"data row6 col4\" >234,600</td>\n",
       "      <td id=\"T_33c0e_row6_col5\" class=\"data row6 col5\" >1,020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120ef7bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #2a4b34; padding: 10px; border-left: 4px solid #4ac656; margin-top: 15px;'>\n",
       "        <p><b>Cheapest model for pipeline:</b> Gemini 2.0 Flash</p>\n",
       "        <p><b>Estimated total cost:</b> $0.0239</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Analyze the cost of a single prompt\n",
    "analyze_prompt_cost(function_prompt, expected_output_length=100)\n",
    "\n",
    "# 2. Analyze the cost of an entire pipeline\n",
    "# For function analysis (all species, 34 regions per species, both hemispheres)\n",
    "analyze_pipeline_cost(\n",
    "    prompt_text=function_prompt,\n",
    "    analysis_type=\"functions\",\n",
    "    species_count=3,                # human, macaque, mouse\n",
    "    regions_per_species=34,         # 34 regions per species\n",
    "    hemisphere_separation=True,     # Left and right hemispheres separately\n",
    "    expected_output_length=100      # Expected output is about 100 characters\n",
    ")\n",
    "\n",
    "# For probability analysis (all species, 34 regions, both hemispheres, 5 functions)\n",
    "analyze_pipeline_cost(\n",
    "    prompt_text=probability_prompt,\n",
    "    analysis_type=\"probability\",\n",
    "    species_count=3,                # human, macaque, mouse\n",
    "    regions_per_species=34,         # 34 regions per species\n",
    "    hemisphere_separation=True,     # Left and right hemispheres separately\n",
    "    functions_count=5,              # Analyzing 5 different functions\n",
    "    expected_output_length=4        # Expected output is a probability (0.XX)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oxford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
